<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Speech & Recording App</title>
  <style>
    body { font-family: Arial, sans-serif; text-align: center; background: #f0f2f5; padding: 20px; }
    h1 { color: #333; }
    .container { max-width: 600px; margin: auto; background: #fff; padding: 20px; border-radius: 10px; box-shadow: 0 2px 6px rgba(0,0,0,0.2); }
    textarea { width: 100%; height: 100px; margin: 10px 0; padding: 10px; }
    button { margin: 5px; padding: 10px 20px; border: none; border-radius: 5px; background: #007bff; color: #fff; cursor: pointer; }
    button:hover { background: #0056b3; }
  </style>
</head>
<body>
  <div class="container">
    <h1>Speech & Recording App</h1>
    <textarea id="textInput" placeholder="Type or speak here..."></textarea>
    <div>
      <button onclick="startRecognition()">üé§ Speak</button>
      <button onclick="stopRecognition()">‚èπ Stop</button>
    </div>
    <div>
      <button onclick="convertTextToSpeech()">üîä Text ‚Üí Speech</button>
      <button onclick="startRecording()">üéô Start Recording</button>
      <button onclick="stopRecording()">‚èπ Stop Recording</button>
    </div>
  </div>

  <script>
    let recognition;
    let mediaRecorder;
    let recordedChunks = [];

    // Speech-to-text
    function startRecognition() {
      if (!('webkitSpeechRecognition' in window)) {
        alert("Speech recognition not supported.");
        return;
      }
      recognition = new webkitSpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = "en-US";
      recognition.onresult = function(event) {
        let text = "";
        for (let i = event.resultIndex; i < event.results.length; i++) {
          text += event.results[i][0].transcript;
        }
        document.getElementById("textInput").value = text;
      };
      recognition.start();
    }

    function stopRecognition() {
      if (recognition) recognition.stop();
    }

    // Text-to-speech
    async function convertTextToSpeech() {
      const text = document.getElementById("textInput").value;
      if (!text) return alert("Please enter some text");
      const res = await fetch("/tts", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text })
      });
      const blob = await res.blob();
      const url = URL.createObjectURL(blob);
      const a = document.createElement("a");
      a.href = url;
      a.download = "speech.mp3";
      a.click();
    }

    // Audio recording
    async function startRecording() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      recordedChunks = [];
      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = e => { if (e.data.size > 0) recordedChunks.push(e.data); };
      mediaRecorder.start();
    }

    async function stopRecording() {
      mediaRecorder.stop();
      mediaRecorder.onstop = async () => {
        const blob = new Blob(recordedChunks, { type: 'audio/webm' });
        const formData = new FormData();
        formData.append("file", blob, "recording.webm");
        const res = await fetch("/upload_audio", { method: "POST", body: formData });
        const mp3Blob = await res.blob();
        const url = URL.createObjectURL(mp3Blob);
        const a = document.createElement("a");
        a.href = url;
        a.download = "recording.mp3";
        a.click();
      };
    }
  </script>
</body>
</html>
